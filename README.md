# В лабораторной работе реализован базовые CRUD-функции с примитивным интерфейсном веб-сайта, а также парсер новостей (https://russian.rt.com)

1. __Парсер новостей:__
Состоит из библиотек (selenium, beautifulsoup, requests)
Сначала, с помощью автоматизированого ПО, мы погружаем дополнительные статьи, количество пролистывания можно настроить в коде, так как сайт является динамическим. Дальше код парсера, по определённым элементам, собирает нужную нам информацию (Название статьи, описание и ссылку). С помощью библиотеки (requests), добавляем собранные данные в базу mysql, используя функцию (post, которая находится в CRUD директории).

2. __CRUD-функции:__
Состоит из библиотек(bottle, pymysql, configparser)
В данной папке реализованы функции (поиска информации по id в базе данных mysql, вывод всех данных из базы, редактирование, добавление и удаление новых записей)
Также данные доступа к базе данных скрыты с помощью (configparser), который читает файл (pymysql.ini) и автоматически выполняет подключение.

## Для запуска нам нужно:

* Указать путь к chromedriver (в коде parserDB)
* Запустить локальный сервер (mysql)
* Создать таблицу в mysql с атрибутами (таблица: news_data_RT; атрибуты: Article, Pre_Body, Link)
* Запустить сначала серверную часть (директория CRUD)
* Запустить парсер и добавление данных с сайта в базу (директория ParserDB)
* Перейти на указанную ссылку локального сайта (Она отображается при запуске кода, директория CRUD)

## На выходе, мы получаем:
Сайт с примитивным функционалом, где мы можем использовать функции (create, read, update и delete), связанные с новостной лентой сайта (https://russian.rt.com). Все данные автоматически добавляются в mysql при запуск кода парсера (директория parserDB).

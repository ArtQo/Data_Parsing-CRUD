# В лабораторной работе реализован базовые CRUD-функции с примитивным интерфейсном веб-сайта, а также парсер новостей сайта (https://russian.rt.com)

1. __Парсер новостей:__
Состоит из библиотек (selenium, beautifulsoup, requests)
Сначала, с помощью автоматизированого ПО, мы погружаем дополнительные статьи, количество пролистывания можно настроить в коде, это делается из-за того, что сайт является динамическим. Дальше код парсера, по определённым элементам, собирает нужную нам информацию (Название статьи, описание и ссылку). А конце, с помощью библиотеки (requests), добавляем собранные данные в базу mysql, используя функцию (post, которая находится в CRUD папке).

2. __CRUD-функции:__
Состоит из библиотек(bottle, pymysql, configparser)
В данной папке реализованы функции (поиска информации по айди во всей базе данных в mysql, вывод всех данных из базы, редактирование, добавление и удаление новых записей)
Также данные доступа к базе данных скрыты с помощью (configparser), который читает, созданный нами, файл pymysql.ini и автоматически выполняет подключение.

## Для запуска нам нужно:

* Указать путь к chromedriver (в коде parserDB)
* Запустить локальный сервер (mysql)
* Создать таблицу в mysql с атрибутами (таблица: news_data_RT; атрибуты: Article, Pre_Body, Link)
* Запустить сначала серверную часть (директория CRUD)
* Запустить парсер и добавление данных с сайта в базу (директория ParserDB)
* Перейти на указанную ссылку локального сайта (Она отображается при запуске кода, директория CRUD)

## На выходе, мы получаем:
Сайт с примитивным функционалом, где мы можем использовать функции (посмотреть, изменить, удалить и добавить записи), связанные с новостной лентой сайта (https://russian.rt.com). Все данные автоматически добавляются в mysql при запуск кода парсера (директория parserDB).
